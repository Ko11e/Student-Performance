{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Find engineer features for Classification and Regression.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/cleaned/TrainSet.csv\n",
        "* inputs/datasets/cleaned/TestSet.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* generate a list with variables to engineer\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "* Feature Engineering Transformers\n",
        "    * Ordinal categorical encoding: `['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities', 'Motivation_Level', 'Internet_Access', 'Family_Income', 'Teacher_Quality', 'School_Type', 'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level', 'Distance_from_Home', 'Gender']`\n",
        "    * Yeo Johnson: `['Attendance', Tutoring-Session', 'Exam_Score']`\n",
        "\n",
        "* A transformer has been developed to create a new column, `Improve_Score`, which is calculated by subtracting the `Previous_Scores` from the `Exam_Score`. This new column contains values of 0 and 1, indicating whether students did not improve or improve their test scores, respectively. Once this new column is added, the `Previous_Scores` and `Exam_Score` columns are removed from the DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Cleaned Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_set_path = \"outputs/datasets/cleaned/TrainSetCleaned.csv\"\n",
        "TrainSet = pd.read_csv(train_set_path)\n",
        "TrainSet.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_path = \"outputs/datasets/cleaned/TrainSetCleaned.csv\"\n",
        "TestSet = pd.read_csv(test_set_path)\n",
        "TestSet.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=TrainSet)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Data Exploration\n",
        "\n",
        "Since the PPS heatmap and values with storng values doesn't differ from the correlation map in the previous notbook other Corraletion and PPS Analaysis. An Analyses will not be made made in this notbooke\n",
        "\n",
        "* There is a strong correlation between Exam_Score and Attendance \n",
        "* Internet_Access data is unbalaced and according to the heatmap there is a low to none corroletion with Exam_Score\n",
        "* Learning_Disabilities data is unbalaced and according to the heatmap there is a low to none corroletion with Exam_Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Potanial Feature Engineering Spreadsheet \n",
        "\n",
        "| Feature                    | Type   | Categorical <br> Encoding | Numerical <br> Transformation | Smart Correlation <br> Selection |\n",
        "|----------------------------|--------|:---------------------:|:-------------------------:|:----------------------------:|\n",
        "| Parental_Involvement       | object |           X           |                           |               X              |\n",
        "| Access_to_Resources        | object |           X           |                           |               X              |\n",
        "| Extracurricular_Activities | object |           X           |                           |               X              |\n",
        "| Motivation_Level           | object |           X           |                           |               X              |\n",
        "| Internet_Access            | object |           X           |                           |               X              |\n",
        "| Family_Income              | object |           X           |                           |               X              |\n",
        "| Teacher_Quality            | object |           X           |                           |               X              |\n",
        "| School_Type                | object |           X           |                           |               X              |\n",
        "| Peer_Influence             | object |           X           |                           |               X              |\n",
        "| Learning_Disabilities      | object |           X           |                           |               X              |\n",
        "| Parental_Education_Level   | object |           X           |                           |               X              |\n",
        "| Distance_from_Home         | object |           X           |                           |               X              |\n",
        "| Gender                     | object |           X           |                           |               X              |\n",
        "|                            |        |                       |                           |                              |\n",
        "| Hours_Studied              | int64  |                       |             X             |               X              |\n",
        "| Attendance                 | int64  |                       |             X             |               X              |\n",
        "| Sleep_Hours                | int64  |                       |             X             |               X              |\n",
        "| Previous_Scores            | int64  |                       |             X             |               X              |\n",
        "| Tutoring_Sessions          | int64  |                       |             X             |               X              |\n",
        "| Physical_Activity          | int64  |                       |             X             |               X              |\n",
        "| Exam_Score                 | int64  |                       |             X             |               X              |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "sns.set(style=\"whitegrid\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def FeatureEngineeringAnalysis(df, analysis_type=None):\n",
        "    \"\"\"\n",
        "    - used for quick feature engineering on numerical and categorical variables\n",
        "    to decide which transformation can better transform the distribution shape\n",
        "    - Once transformed, use a reporting tool, like ydata-profiling, to evaluate distributions\n",
        "    \"\"\"\n",
        "    check_missing_values(df)\n",
        "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
        "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
        "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
        "\n",
        "    # Loop in each variable and engineer the data according to the analysis type\n",
        "    df_feat_eng = pd.DataFrame([])\n",
        "    for column in df.columns:\n",
        "        # create additional columns (column_method) to apply the methods\n",
        "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
        "        for method in list_column_transformers:\n",
        "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
        "\n",
        "        # Apply transformers in respective column_transformers\n",
        "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
        "            analysis_type, df_feat_eng, column)\n",
        "\n",
        "        # For each variable, assess how the transformations perform\n",
        "        transformer_evaluation(\n",
        "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
        "\n",
        "    return df_feat_eng\n",
        "\n",
        "\n",
        "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
        "    \"\"\" Check analysis type \"\"\"\n",
        "    if analysis_type is None:\n",
        "        raise SystemExit(\n",
        "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
        "    if analysis_type not in allowed_types:\n",
        "        raise SystemExit(\n",
        "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
        "\n",
        "\n",
        "def check_missing_values(df):\n",
        "    if df.isna().sum().sum() != 0:\n",
        "        raise SystemExit(\n",
        "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
        "\n",
        "\n",
        "def define_list_column_transformers(analysis_type):\n",
        "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
        "    if analysis_type == 'numerical':\n",
        "        list_column_transformers = [\n",
        "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
        "\n",
        "    elif analysis_type == 'ordinal_encoder':\n",
        "        list_column_transformers = [\"ordinal_encoder\"]\n",
        "\n",
        "    elif analysis_type == 'outlier_winsorizer':\n",
        "        list_column_transformers = ['iqr']\n",
        "\n",
        "    return list_column_transformers\n",
        "\n",
        "\n",
        "def apply_transformers(analysis_type, df_feat_eng, column):\n",
        "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
        "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
        "\n",
        "    if analysis_type == 'numerical':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    elif analysis_type == 'outlier_winsorizer':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    elif analysis_type == 'ordinal_encoder':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    return df_feat_eng, list_applied_transformers\n",
        "\n",
        "\n",
        "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
        "    # For each variable, assess how the transformations perform\n",
        "    print(f\"* Variable Analyzed: {column}\")\n",
        "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
        "    for col in [column] + list_applied_transformers:\n",
        "\n",
        "        if analysis_type != 'ordinal_encoder':\n",
        "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "        else:\n",
        "            if col == column:\n",
        "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
        "            else:\n",
        "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.countplot(data=df_feat_eng, x=col, palette=[\n",
        "                  '#432371'], order=df_feat_eng[col].value_counts().index)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Numerical(df, variable):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
        "    stats.probplot(df[variable], dist=\"norm\", rvalue=True, plot=axes[1])\n",
        "    sns.boxplot(x=df[variable], ax=axes[2])\n",
        "\n",
        "    axes[0].set_title('Histogram')\n",
        "    axes[1].set_title('QQ Plot')\n",
        "    axes[2].set_title('Boxplot')\n",
        "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "    try:\n",
        "        encoder = OrdinalEncoder(encoding_method='arbitrary', variables=[\n",
        "                                 f\"{column}_ordinal_encoder\"])\n",
        "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
        "\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "\n",
        "    # Winsorizer iqr\n",
        "    try:\n",
        "        disc = Winsorizer(\n",
        "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
        "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_iqr\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_Numerical(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "\n",
        "    # LogTransformer base e\n",
        "    try:\n",
        "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
        "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_log_e\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
        "\n",
        "    # LogTransformer base 10\n",
        "    try:\n",
        "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
        "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_log_10\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
        "\n",
        "    # ReciprocalTransformer\n",
        "    try:\n",
        "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
        "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
        "\n",
        "    # PowerTransformer\n",
        "    try:\n",
        "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
        "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_power\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
        "\n",
        "    # BoxCoxTransformer\n",
        "    try:\n",
        "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
        "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_box_cox\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
        "\n",
        "    # YeoJohnsonTransformer\n",
        "    try:\n",
        "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
        "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_engineering_object = ['Parental_Involvement', 'Access_to_Resources',\n",
        "                                'Extracurricular_Activities', 'Motivation_Level',\n",
        "                                'Internet_Access', 'Family_Income', 'Teacher_Quality',\n",
        "                                'School_Type', 'Peer_Influence', 'Learning_Disabilities',\n",
        "                                'Parental_Education_Level', 'Distance_from_Home', 'Gender']\n",
        "\n",
        "variables_engineering_num = ['Hours_Studied', 'Attendance', 'Sleep_Hours',\n",
        "                             'Previous_Scores', 'Tutoring_Sessions', \n",
        "                             'Physical_Activity', 'Exam_Score']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering_object = TrainSet[variables_engineering_object].copy()\n",
        "df_engineering_object.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering_num = TrainSet[variables_engineering_num].copy()\n",
        "df_engineering_num.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering_object = FeatureEngineeringAnalysis(df=df_engineering_object, analysis_type='ordinal_encoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering_num = FeatureEngineeringAnalysis(df=df_engineering_num, analysis_type='numerical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = OrdinalEncoder(encoding_method='arbitrary', variables = variables_engineering_object)\n",
        "TrainSet = encoder.fit_transform(TrainSet)\n",
        "TestSet = encoder.transform(TestSet)\n",
        "\n",
        "print(\"* Categorical encoding - ordinal transformation done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make a copy of the training dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = TrainSet.copy()\n",
        "df_engineering.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "corr_sel6 = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")\n",
        "corr_sel6.fit_transform(df_engineering)\n",
        "\n",
        "corr_sel7 = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.7, selection_method=\"variance\")\n",
        "corr_sel7.fit_transform(df_engineering)\n",
        "\n",
        "print(f'Correlated feature sets with threshold 0.6: {corr_sel6.correlated_feature_sets_}')\n",
        "print(f'Features to drop: {corr_sel6.features_to_drop_}')\n",
        "print('--------------------------')\n",
        "print(f'Correlated feature sets with threshold 0.7: {corr_sel7.correlated_feature_sets_}')\n",
        "print(f'Features to drop: {corr_sel7.features_to_drop_}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The transformer finds a correlation between the feature Attenced and Exam_Score when running the SmartCorrelatedSelection with the `threshold = 0.6`. Since Exam_Score has the highest variance of the values, the transformer will try to drop Exam_Score, which is the goal of the business case. This can be solved by increasing the threshold to `0.7`, but this will result in none of the features being dropped, leading to the conclusion that the SmartCorrelatedSelection will not be applied.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering Spreadsheet Summary\n",
        "\n",
        "| Feature                    | Type   | Categorical <br> Encoding | Numerical <br> Transformation | Smart Correlation <br> Selection |\n",
        "|----------------------------|--------|:---------------------:|:-------------------------:|:----------------------------:|\n",
        "| Parental_Involvement       | object |           X           |                           |                             |\n",
        "| Access_to_Resources        | object |           X           |                           |                             |\n",
        "| Extracurricular_Activities | object |           X           |                           |                             |\n",
        "| Motivation_Level           | object |           X           |                           |                             |\n",
        "| Internet_Access            | object |           X           |                           |                             |\n",
        "| Family_Income              | object |           X           |                           |                             |\n",
        "| Teacher_Quality            | object |           X           |                           |                             |\n",
        "| School_Type                | object |           X           |                           |                             |\n",
        "| Peer_Influence             | object |           X           |                           |                             |\n",
        "| Learning_Disabilities      | object |           X           |                           |                             |\n",
        "| Parental_Education_Level   | object |           X           |                           |                             |\n",
        "| Distance_from_Home         | object |           X           |                           |                             |\n",
        "| Gender                     | object |           X           |                           |                             |\n",
        "|                            |        |                       |                           |                             |\n",
        "| Hours_Studied              | int64  |                       |                           |                             |\n",
        "| Attendance                 | int64  |                       |             X             |                             |\n",
        "| Sleep_Hours                | int64  |                       |                           |                             |\n",
        "| Previous_Scores            | int64  |                       |                           |                             |\n",
        "| Tutoring_Sessions          | int64  |                       |             X             |                             |\n",
        "| Physical_Activity          | int64  |                       |                           |                             |\n",
        "| Exam_Score                 | int64  |                       |             X             |                             |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Transformer\n",
        "\n",
        "## Create improved column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class CreateImprovedScoreColumn(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()  # To avoid modifying the original data\n",
        "        new_value = X['Exam_Score'] - X['Previous_Scores']\n",
        "        X['Improved_Score'] = new_value\n",
        "\n",
        "        # Replace negative and zero values with 0, positive values with 1\n",
        "        X['Improved_Score'] = X['Improved_Score'].apply(lambda x: 1 if x > 0 else 0)\n",
        "        \n",
        "        # Drop the original columns Previous_Scores and Exam_Score\n",
        "        X.drop(['Previous_Scores', 'Exam_Score'], axis=1, inplace=True)\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Transformer_improve = CreateImprovedScoreColumn()\n",
        "df_ex = Transformer_improve.fit_transform(TrainSet)\n",
        "df_ex.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pandas_report = ProfileReport(df=df_ex)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
