{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Prediction with Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fit and evaluate a regression model to predict Students Exam Score.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/StudentPerformance.csv\n",
        "* Instructions on which variables to use for data cleaning and feature engineering. They are found in their respective notebooks.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Train set (features and target)\n",
        "* Test set (features and target)\n",
        "* ML pipeline to predict Exam Score\n",
        "* labels map\n",
        "* Feature Importance Plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Student-Performance/jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Student-Performance'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6607, 20)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours_Studied</th>\n",
              "      <th>Attendance</th>\n",
              "      <th>Parental_Involvement</th>\n",
              "      <th>Access_to_Resources</th>\n",
              "      <th>Extracurricular_Activities</th>\n",
              "      <th>Sleep_Hours</th>\n",
              "      <th>Previous_Scores</th>\n",
              "      <th>Motivation_Level</th>\n",
              "      <th>Internet_Access</th>\n",
              "      <th>Tutoring_Sessions</th>\n",
              "      <th>Family_Income</th>\n",
              "      <th>Teacher_Quality</th>\n",
              "      <th>School_Type</th>\n",
              "      <th>Peer_Influence</th>\n",
              "      <th>Physical_Activity</th>\n",
              "      <th>Learning_Disabilities</th>\n",
              "      <th>Parental_Education_Level</th>\n",
              "      <th>Distance_from_Home</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Exam_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>84</td>\n",
              "      <td>Low</td>\n",
              "      <td>High</td>\n",
              "      <td>No</td>\n",
              "      <td>7</td>\n",
              "      <td>73</td>\n",
              "      <td>Low</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Public</td>\n",
              "      <td>Positive</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>High School</td>\n",
              "      <td>Near</td>\n",
              "      <td>Male</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19</td>\n",
              "      <td>64</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>No</td>\n",
              "      <td>8</td>\n",
              "      <td>59</td>\n",
              "      <td>Low</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Public</td>\n",
              "      <td>Negative</td>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>College</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Female</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24</td>\n",
              "      <td>98</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Yes</td>\n",
              "      <td>7</td>\n",
              "      <td>91</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Public</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>Postgraduate</td>\n",
              "      <td>Near</td>\n",
              "      <td>Male</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Hours_Studied  Attendance Parental_Involvement Access_to_Resources  \\\n",
              "0             23          84                  Low                High   \n",
              "1             19          64                  Low              Medium   \n",
              "2             24          98               Medium              Medium   \n",
              "\n",
              "  Extracurricular_Activities  Sleep_Hours  Previous_Scores Motivation_Level  \\\n",
              "0                         No            7               73              Low   \n",
              "1                         No            8               59              Low   \n",
              "2                        Yes            7               91           Medium   \n",
              "\n",
              "  Internet_Access  Tutoring_Sessions Family_Income Teacher_Quality  \\\n",
              "0             Yes                  0           Low          Medium   \n",
              "1             Yes                  2        Medium          Medium   \n",
              "2             Yes                  2        Medium          Medium   \n",
              "\n",
              "  School_Type Peer_Influence  Physical_Activity Learning_Disabilities  \\\n",
              "0      Public       Positive                  3                    No   \n",
              "1      Public       Negative                  4                    No   \n",
              "2      Public        Neutral                  4                    No   \n",
              "\n",
              "  Parental_Education_Level Distance_from_Home  Gender  Exam_Score  \n",
              "0              High School               Near    Male          67  \n",
              "1                  College           Moderate  Female          61  \n",
              "2             Postgraduate               Near    Male          74  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/StudentPerformance.csv\")\n",
        "      )\n",
        "\n",
        "print(df.shape)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# ML Pipline: Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create ML pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Cleaning\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "# Feature Engineering\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine.transformation import YeoJohnsonTransformer\n",
        "from feature_engine.discretisation import EqualFrequencyDiscretiser \n",
        "\n",
        "# Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        ('categorical_imputer', CategoricalImputer(imputation_method='missing',\n",
        "                                                    fill_value='Missing',\n",
        "                                                    variables=['Teacher_Quality', 'Parental_Education_Level', 'Distance_from_Home'])),\n",
        "\n",
        "        (\"Ordinal_Encoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                           variables=['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',\n",
        "                                                      'Motivation_Level', 'Internet_Access', 'Family_Income', 'Teacher_Quality',\n",
        "                                                      'School_Type', 'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level',\n",
        "                                                      'Distance_from_Home', 'Gender'])),\n",
        "        \n",
        "        (\"YeoJohnson\", YeoJohnsonTransformer(variables=['Attendance', 'Tutoring_Sessions'])),\n",
        "\n",
        "        (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "        (\"feat_selection\",  SelectFromModel(model)),\n",
        "\n",
        "        (\"model\", model),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom Class for hyperparameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model = PipelineOptimization(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Train set: (5285, 19) (5285,) \n",
            "* Test set: (1322, 19) (1322,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(['Exam_Score'], axis=1) # Defining the features\n",
        "y = df['Exam_Score'] # Defining the the target for the prediction\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X,\n",
        "     y,\n",
        "     test_size=0.2,\n",
        "     random_state=0\n",
        " )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
        "       \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search CV - Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "\n",
        "params_quick_search = {\n",
        "    'LinearRegression': {},\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do a hyperparameter optimisation search using default hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the resulte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression</td>\n",
              "      <td>0.494062</td>\n",
              "      <td>0.641766</td>\n",
              "      <td>0.764155</td>\n",
              "      <td>0.089603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.443837</td>\n",
              "      <td>0.551627</td>\n",
              "      <td>0.652642</td>\n",
              "      <td>0.071278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBRegressor</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.516318</td>\n",
              "      <td>0.611245</td>\n",
              "      <td>0.070621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestRegressor</td>\n",
              "      <td>0.338651</td>\n",
              "      <td>0.481695</td>\n",
              "      <td>0.607583</td>\n",
              "      <td>0.087903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ExtraTreesRegressor</td>\n",
              "      <td>0.281325</td>\n",
              "      <td>0.382418</td>\n",
              "      <td>0.52964</td>\n",
              "      <td>0.095395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeRegressor</td>\n",
              "      <td>-0.027753</td>\n",
              "      <td>0.112576</td>\n",
              "      <td>0.245693</td>\n",
              "      <td>0.106021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AdaBoostRegressor</td>\n",
              "      <td>-1.194011</td>\n",
              "      <td>-0.455568</td>\n",
              "      <td>0.343277</td>\n",
              "      <td>0.563316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   estimator min_score mean_score max_score std_score\n",
              "0           LinearRegression  0.494062   0.641766  0.764155  0.089603\n",
              "5  GradientBoostingRegressor  0.443837   0.551627  0.652642  0.071278\n",
              "6               XGBRegressor  0.407407   0.516318  0.611245  0.070621\n",
              "2      RandomForestRegressor  0.338651   0.481695  0.607583  0.087903\n",
              "3        ExtraTreesRegressor  0.281325   0.382418   0.52964  0.095395\n",
              "1      DecisionTreeRegressor -0.027753   0.112576  0.245693  0.106021\n",
              "4          AdaBoostRegressor -1.194011  -0.455568  0.343277  0.563316"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since LinearRegssion doesn't have so many hyperparameter, the model GradientBoostRegressor will also be explored to see if the Model be improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    # 'LinearRegression': LinearRegression(),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    # 'LinearRegression': {\n",
        "    #     'model__positive': [True, False],\n",
        "    #     'model__n_jobs':[None, 1, 2]\n",
        "    # },\n",
        "    \"GradientBoostingRegressor\": {\n",
        "        'model__learning_rate': [0.05, 0.1],\n",
        "        'model__n_estimators': [100, 200, 300],\n",
        "        'model__max_depth': [3, 5],\n",
        "        'model__min_samples_split': [2, 5, 10],\n",
        "        'model__min_samples_leaf': [1, 2],\n",
        "        'model__max_leaf_nodes': [10],\n",
        "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
        "        'model__subsample': [0.8, 1.0],\n",
        "        'model__max_features': ['sqrt', 'log2'] \n",
        "    },\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for GradientBoostingRegressor \n",
            "\n",
            "Fitting 5 folds for each of 2916 candidates, totalling 14580 fits\n"
          ]
        }
      ],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>model__learning_rate</th>\n",
              "      <th>model__max_depth</th>\n",
              "      <th>model__max_features</th>\n",
              "      <th>model__max_leaf_nodes</th>\n",
              "      <th>model__min_samples_leaf</th>\n",
              "      <th>model__min_samples_split</th>\n",
              "      <th>model__n_estimators</th>\n",
              "      <th>model__subsample</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.446847</td>\n",
              "      <td>0.556504</td>\n",
              "      <td>0.663426</td>\n",
              "      <td>0.072982</td>\n",
              "      <td>0.05</td>\n",
              "      <td>3</td>\n",
              "      <td>log2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.446847</td>\n",
              "      <td>0.556504</td>\n",
              "      <td>0.663426</td>\n",
              "      <td>0.072982</td>\n",
              "      <td>0.05</td>\n",
              "      <td>3</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.44674</td>\n",
              "      <td>0.556464</td>\n",
              "      <td>0.663597</td>\n",
              "      <td>0.073082</td>\n",
              "      <td>0.05</td>\n",
              "      <td>3</td>\n",
              "      <td>log2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1152</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.44674</td>\n",
              "      <td>0.556464</td>\n",
              "      <td>0.663597</td>\n",
              "      <td>0.073082</td>\n",
              "      <td>0.05</td>\n",
              "      <td>3</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.44674</td>\n",
              "      <td>0.556446</td>\n",
              "      <td>0.663411</td>\n",
              "      <td>0.073031</td>\n",
              "      <td>0.05</td>\n",
              "      <td>3</td>\n",
              "      <td>log2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.296803</td>\n",
              "      <td>0.408105</td>\n",
              "      <td>0.484977</td>\n",
              "      <td>0.062931</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.296803</td>\n",
              "      <td>0.408105</td>\n",
              "      <td>0.484977</td>\n",
              "      <td>0.062931</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>log2</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.296803</td>\n",
              "      <td>0.408105</td>\n",
              "      <td>0.484977</td>\n",
              "      <td>0.062931</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>log2</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.296803</td>\n",
              "      <td>0.408105</td>\n",
              "      <td>0.484977</td>\n",
              "      <td>0.062931</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.296803</td>\n",
              "      <td>0.408105</td>\n",
              "      <td>0.484977</td>\n",
              "      <td>0.062931</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2916 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      estimator min_score mean_score max_score std_score  \\\n",
              "1242  GradientBoostingRegressor  0.446847   0.556504  0.663426  0.072982   \n",
              "1134  GradientBoostingRegressor  0.446847   0.556504  0.663426  0.072982   \n",
              "1260  GradientBoostingRegressor   0.44674   0.556464  0.663597  0.073082   \n",
              "1152  GradientBoostingRegressor   0.44674   0.556464  0.663597  0.073082   \n",
              "1251  GradientBoostingRegressor   0.44674   0.556446  0.663411  0.073031   \n",
              "...                         ...       ...        ...       ...       ...   \n",
              "146   GradientBoostingRegressor  0.296803   0.408105  0.484977  0.062931   \n",
              "254   GradientBoostingRegressor  0.296803   0.408105  0.484977  0.062931   \n",
              "263   GradientBoostingRegressor  0.296803   0.408105  0.484977  0.062931   \n",
              "119   GradientBoostingRegressor  0.296803   0.408105  0.484977  0.062931   \n",
              "110   GradientBoostingRegressor  0.296803   0.408105  0.484977  0.062931   \n",
              "\n",
              "     model__learning_rate model__max_depth model__max_features  \\\n",
              "1242                 0.05                3                log2   \n",
              "1134                 0.05                3                sqrt   \n",
              "1260                 0.05                3                log2   \n",
              "1152                 0.05                3                sqrt   \n",
              "1251                 0.05                3                log2   \n",
              "...                   ...              ...                 ...   \n",
              "146                  0.01                3                sqrt   \n",
              "254                  0.01                3                log2   \n",
              "263                  0.01                3                log2   \n",
              "119                  0.01                3                sqrt   \n",
              "110                  0.01                3                sqrt   \n",
              "\n",
              "     model__max_leaf_nodes model__min_samples_leaf model__min_samples_split  \\\n",
              "1242                    10                       1                        2   \n",
              "1134                    10                       1                        2   \n",
              "1260                    10                       1                       10   \n",
              "1152                    10                       1                       10   \n",
              "1251                    10                       1                        5   \n",
              "...                    ...                     ...                      ...   \n",
              "146                   None                       2                        5   \n",
              "254                   None                       2                        5   \n",
              "263                   None                       2                       10   \n",
              "119                   None                       1                        5   \n",
              "110                   None                       1                        2   \n",
              "\n",
              "     model__n_estimators model__subsample  \n",
              "1242                 100              0.8  \n",
              "1134                 100              0.8  \n",
              "1260                 100              0.8  \n",
              "1152                 100              0.8  \n",
              "1251                 100              0.8  \n",
              "...                  ...              ...  \n",
              "146                  100              1.0  \n",
              "254                  100              1.0  \n",
              "263                  100              1.0  \n",
              "119                  100              1.0  \n",
              "110                  100              1.0  \n",
              "\n",
              "[2916 rows x 13 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick Conclusion\n",
        "\n",
        "To find a model with a mean score of at least 0.8, as specified in the business case, the data underwent cleaning and feature engineering, which were detailed in previous notebooks. Various models were tested, and it was observed that the model with the highest mean score was LinearRegression, achieving approximately 0.64, followed by GradientBoostingRegressor with a score of around 0.55. \n",
        "\n",
        "Due to LinearRegression having very few hyperparameters, GradientBoostingRegressor was also explored to see if its performance could be enhanced through hyperparameter tuning. In the first attempt to improve the model using hyperparameters, it was evident that LinearRegression still maintained the highest mean score, although there was no improvement in the score itself. \n",
        "\n",
        "In the second attempt, the LinearRegression model was removed, and more hyperparameters were introduced to assess potential improvements. However, the results indicated that LinearRegression continued to have the best mean score.\n",
        "\n",
        "**Score for the LinearRegresson and the quick search**\n",
        "|estimator | min_score | mean_score | max_score | std_score | \n",
        "|:----     |----       |----        |----       |----       |\n",
        "|LinearRegression |\t0.494062 | 0.641766 | 0.764155 | 0.089603 |\n",
        "\n",
        "**Attempt two to improve the model with the hyperparameters**\n",
        "|no. |estimator | min_score | mean_score | max_score | std_score | \n",
        "|:---|:----     |----       |----        |----       |----       |\n",
        "|1242 | GradientBoostingRegressor | 0.446847 | 0.556504 | 0.663426 | 0.072982 |\n",
        "|1134 | GradientBoostingRegressor | 0.446847 | 0.556504 | 0.663426 |\t0.072982 |\t\n",
        "|1260 | GradientBoostingRegressor | 0.44674  | 0.556464 | 0.663597 | 0.073082 |\t\n",
        "|1152 | GradientBoostingRegressor | 0.44674  | 0.556464 | 0.663597 |\t0.073082 |\t\n",
        "|1251 | GradientBoostingRegressor | 0.44674 | 0.556446 | 0.663411 | 0.073031 |\n",
        "\n",
        "The next step is to explore if the model will have a better result with the NaN values replaced with the most frequent values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create ML pipeline with Missing values to most fequent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import CategoricalImputer, DropMissingData\n",
        "\n",
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        ('categorical_imputer', CategoricalImputer(imputation_method='frequent',\n",
        "                                                   variables=['Teacher_Quality', 'Parental_Education_Level', 'Distance_from_Home'])),\n",
        "\n",
        "        (\"Ordinal_Encoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                           variables=['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',\n",
        "                                                      'Motivation_Level', 'Internet_Access', 'Family_Income', 'Teacher_Quality',\n",
        "                                                      'School_Type', 'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level',\n",
        "                                                      'Distance_from_Home', 'Gender'])),\n",
        "        \n",
        "        (\"YeoJohnson\", YeoJohnsonTransformer(variables=['Attendance', 'Tutoring_Sessions'])),\n",
        "\n",
        "        (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "        (\"feat_selection\",  SelectFromModel(model)),\n",
        "\n",
        "        (\"model\", model),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for LinearRegression \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for DecisionTreeRegressor \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for RandomForestRegressor \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for ExtraTreesRegressor \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for AdaBoostRegressor \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for GradientBoostingRegressor \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for XGBRegressor \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        }
      ],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression</td>\n",
              "      <td>0.530141</td>\n",
              "      <td>0.630419</td>\n",
              "      <td>0.690003</td>\n",
              "      <td>0.053237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.429427</td>\n",
              "      <td>0.547969</td>\n",
              "      <td>0.624965</td>\n",
              "      <td>0.064219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBRegressor</td>\n",
              "      <td>0.355214</td>\n",
              "      <td>0.493917</td>\n",
              "      <td>0.576832</td>\n",
              "      <td>0.078367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestRegressor</td>\n",
              "      <td>0.403796</td>\n",
              "      <td>0.458818</td>\n",
              "      <td>0.51495</td>\n",
              "      <td>0.036278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ExtraTreesRegressor</td>\n",
              "      <td>0.343208</td>\n",
              "      <td>0.398857</td>\n",
              "      <td>0.468127</td>\n",
              "      <td>0.04184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeRegressor</td>\n",
              "      <td>-0.161578</td>\n",
              "      <td>0.024558</td>\n",
              "      <td>0.188947</td>\n",
              "      <td>0.147951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AdaBoostRegressor</td>\n",
              "      <td>-0.172119</td>\n",
              "      <td>-0.021568</td>\n",
              "      <td>0.20844</td>\n",
              "      <td>0.134745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   estimator min_score mean_score max_score std_score\n",
              "0           LinearRegression  0.530141   0.630419  0.690003  0.053237\n",
              "5  GradientBoostingRegressor  0.429427   0.547969  0.624965  0.064219\n",
              "6               XGBRegressor  0.355214   0.493917  0.576832  0.078367\n",
              "2      RandomForestRegressor  0.403796   0.458818   0.51495  0.036278\n",
              "3        ExtraTreesRegressor  0.343208   0.398857  0.468127   0.04184\n",
              "1      DecisionTreeRegressor -0.161578   0.024558  0.188947  0.147951\n",
              "4          AdaBoostRegressor -0.172119  -0.021568   0.20844  0.134745"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick Conclusion\n",
        "\n",
        "In this section, we replaced the missing values with the most frequent value for each specific feature, instead of labeling them as 'Missing'. This approach aimed to improve the model's performance. We tested various models; however, further investigation with hyperparameters was determined to be unnecessary. The results showed that changing the NaN values to the most frequent values in the features had no significant impact. Since there were no major differences observed, the subsequent tests will use the method of replacing NaN values with 'Missing'.\n",
        "\n",
        "The next step in this notebook is to explore a model called KNeighborsRegressor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Pipline modified for KNeighborsRegressor\n",
        "\n",
        "The KNeighborsRegressor is a non-parametric regression method that predicts values based on the k closest training data points. It stores the training data and uses a distance metric, usually Euclidean distance, to make predictions.\n",
        "\n",
        "For each prediction, the average of the target values of the k nearest points is calculated. This can be done with uniform weighting or by considering distance. Choosing the right value for k is crucial: smaller values may result in high variance, while larger values can lead to high bias. Therefore, the function below examines the optimal k-value, along with the mean R² value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization_KNN(model):\n",
        "    steps = [\n",
        "        ('categorical_imputer', CategoricalImputer(imputation_method='missing',\n",
        "                                                    fill_value='Missing',\n",
        "                                                    variables=['Teacher_Quality', 'Parental_Education_Level', 'Distance_from_Home'])),\n",
        "        (\"Ordinal_Encoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                           variables=['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',\n",
        "                                                      'Motivation_Level', 'Internet_Access', 'Family_Income', 'Teacher_Quality',\n",
        "                                                      'School_Type', 'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level',\n",
        "                                                      'Distance_from_Home', 'Gender'])),\n",
        "        (\"YeoJohnson\", YeoJohnsonTransformer(['Attendance', 'Tutoring_Sessions'])),\n",
        "        (\"feat_scaling\", StandardScaler())\n",
        "    ]\n",
        "    \n",
        "    # Add feature selection step only if the model has feature_importances_ or coef_ attributes\n",
        "    if hasattr(model, 'feature_importances_') or hasattr(model, 'coef_'):\n",
        "        steps.append((\"feat_selection\", SelectFromModel(model)))\n",
        "\n",
        "    steps.append((\"model\", model))\n",
        "    \n",
        "    pipeline_base = Pipeline(steps)\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The max value is 0.4677504653592591 and as the k-value 19\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def Predict_k_value(X_train, y_train, X_test, y_test, k_max):\n",
        "    knn_r_score=[]\n",
        "\n",
        "    for i in range(1, k_max):\n",
        "        # Create and fit the KNeighborsRegressor\n",
        "        knn_pipeline = PipelineOptimization_KNN(KNeighborsRegressor(n_neighbors=i, weights='distance', algorithm='ball_tree'))\n",
        "        knn_pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = knn_pipeline.predict(X_test)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        knn_r_score.append(r2)\n",
        "\n",
        "    print(f'The max value is {max(knn_r_score)} and as the k-value {knn_r_score.index(max(knn_r_score))}')\n",
        "    plt.plot(range(1, k_max), knn_r_score)\n",
        "    plt.show\n",
        "\n",
        "Predict_k_value(X_train, y_train, X_test, y_test, 201)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick Conclusion\n",
        "\n",
        "As previously discussed, an alternative approach was attempted to improve the model. In this case, the KNeighborsRegressor model was utilized, and a function was created to determine the optimal k value. The most suitable k-value found was 19, however, the mean score for the R² value was approximately 0.47, which is much lower than the scores obtained in previous sections.\n",
        "\n",
        "In the next section, a pipeline will be developed using PCA to enhance the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create ML Pipline with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = (pd.read_csv(\"outputs/datasets/collection/StudentPerformance.csv\")\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = PipelineOptimization(model=LinearRegression())\n",
        "pipeline_pca = Pipeline(pipeline.steps[:3])\n",
        "df_pca = pipeline_pca.fit_transform(df.drop(['Exam_Score'], axis=1))\n",
        "\n",
        "print(df_pca.shape,'\\n', type(df_pca))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_components = 19\n",
        "\n",
        "\n",
        "def pca_components_analysis(df_pca, n_components):\n",
        "    pca = PCA(n_components=n_components).fit(df_pca)\n",
        "    x_PCA = pca.transform(df_pca)  # array with transformed PCA\n",
        "\n",
        "    ComponentsList = [\"Component \" + str(number)\n",
        "                      for number in range(n_components)]\n",
        "    dfExplVarRatio = pd.DataFrame(\n",
        "        data=np.round(100 * pca.explained_variance_ratio_, 3),\n",
        "        index=ComponentsList,\n",
        "        columns=['Explained Variance Ratio (%)'])\n",
        "\n",
        "    dfExplVarRatio['Accumulated Variance'] = dfExplVarRatio['Explained Variance Ratio (%)'].cumsum(\n",
        "    )\n",
        "\n",
        "    PercentageOfDataExplained = dfExplVarRatio['Explained Variance Ratio (%)'].sum(\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"* The {n_components} components explain {round(PercentageOfDataExplained,2)}% of the data \\n\")\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.lineplot(data=dfExplVarRatio,  marker=\"o\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(np.arange(0, 110, 10))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "pca_components_analysis(df_pca=df_pca, n_components=n_components)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_components = 6\n",
        "pca_components_analysis(df_pca=df_pca, n_components=n_components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rewrite ML Pipline for Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        ('categorical_imputer', CategoricalImputer(imputation_method='frequent',\n",
        "                                                    variables=['Teacher_Quality', 'Parental_Education_Level', 'Distance_from_Home'])),\n",
        "\n",
        "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                     variables=['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',\n",
        "                                                                'Motivation_Level', 'Internet_Access', 'Family_Income', 'Teacher_Quality',\n",
        "                                                                'School_Type', 'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level',\n",
        "                                                                'Distance_from_Home', 'Gender'])),\n",
        "        \n",
        "        (\"YeoJohnson\", YeoJohnsonTransformer(variables=['Attendance', 'Tutoring_Sessions'])),\n",
        "\n",
        "        (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "        # PCA replace Feature Selection\n",
        "        (\"PCA\", PCA(n_components=6, random_state=0)),\n",
        "\n",
        "        (\"model\", model),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quick_search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "quick_search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recreate Pipline and tagets to Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        ('categorical_imputer', CategoricalImputer(imputation_method='frequent',\n",
        "                                                    variables=['Teacher_Quality', 'Parental_Education_Level', 'Distance_from_Home'])),\n",
        "\n",
        "        (\"Ordinal_Encoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                           variables=['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',\n",
        "                                                      'Motivation_Level', 'Internet_Access', 'Family_Income', 'Teacher_Quality',\n",
        "                                                      'School_Type', 'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level',\n",
        "                                                      'Distance_from_Home', 'Gender'])),\n",
        "        \n",
        "        (\"YeoJohnson\", YeoJohnsonTransformer(variables=['Attendance', 'Tutoring_Sessions'])),\n",
        "\n",
        "        (\"feat_scaling\", StandardScaler()),\n",
        "\n",
        "        (\"feat_selection\",  SelectFromModel(model)),\n",
        "\n",
        "        (\"model\", model),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "pipeline_taget_cleaning = Pipeline([\n",
        "      ('efd', EqualFrequencyDiscretiser(q=5, variables=['Exam_Score'] ))\n",
        "])\n",
        "\n",
        "\n",
        "df_target_bins = pipeline_taget_cleaning.fit_transform(df)\n",
        "\n",
        "target_span = pipeline_taget_cleaning['efd'].binner_dict_\n",
        "\n",
        "df.head()\n",
        "\n",
        "sns.countplot(data=df_target_bins, x='Exam_Score')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X = df.drop(['Exam_Score'], axis=1) # Defining the features\n",
        "y = df['Exam_Score'] # Defining the the target for the prediction\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X,\n",
        "     y,\n",
        "     test_size=0.2,\n",
        "     random_state=0\n",
        " )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
        "       \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "models_quick_search = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0, multi_class='auto', solver='lbfgs'),\n",
        "    # \"XGBClassifier\": XGBClassifier(random_state=0, use_label_encoder=False),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LogisticRegression\": {},\n",
        "    # \"XGBClassifier\": {},\n",
        "    \"DecisionTreeClassifier\": {},\n",
        "    \"RandomForestClassifier\": {},\n",
        "    \"GradientBoostingClassifier\": {},\n",
        "    \"ExtraTreesClassifier\": {},\n",
        "    \"AdaBoostClassifier\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(recall_score, pos_label=1),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick Conclusion\n",
        "Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimize ML\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[1,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
        "    print(\"Model Evaluation \\n\")\n",
        "    print(\"* Train Set\")\n",
        "    regression_evaluation(X_train, y_train, pipeline)\n",
        "    print(\"* Test Set\")\n",
        "    regression_evaluation(X_test, y_test, pipeline)\n",
        "\n",
        "\n",
        "def regression_evaluation(X, y, pipeline):\n",
        "    prediction = pipeline.predict(X)\n",
        "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
        "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
        "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
        "    print('Root Mean Squared Error:', np.sqrt(\n",
        "        mean_squared_error(y, prediction)).round(3))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
        "    pred_train = pipeline.predict(X_train)\n",
        "    pred_test = pipeline.predict(X_test)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
        "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
        "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
        "    axes[0].set_xlabel(\"Actual\")\n",
        "    axes[0].set_ylabel(\"Predictions\")\n",
        "    axes[0].set_title(\"Train Set\")\n",
        "\n",
        "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
        "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
        "    axes[1].set_xlabel(\"Actual\")\n",
        "    axes[1].set_ylabel(\"Predictions\")\n",
        "    axes[1].set_title(\"Test Set\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test,\n",
        "                            best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
